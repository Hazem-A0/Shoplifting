{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6bbp9N+HSLxJ3GSr7Z5EV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hazem-A0/Shoplifting/blob/main/2Dcnn%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt2-J_6nfNmV",
        "outputId": "66ec6282-eb61-4f4a-e1fc-3ba74bcafa75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Shop_DataSet.zip -d /content/drive/MyDrive/Shop_DataSet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsG2o_eZfQjJ",
        "outputId": "d7fefa20-41e1-4164-e33a-4c97a1381b2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Shop_DataSet.zip\n",
            "   creating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/\n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_0.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_0_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_1_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_10.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_10_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_100.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_100_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_101.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_101_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_102.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_102_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_103.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_103_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_104.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_104_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_105.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_105_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_106.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_106_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_107.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_107_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_108.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_108_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_109.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_109_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_11.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_11_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_110.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_110_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_111.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_111_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_112.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_112_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_113.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_113_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_114.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_114_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_115.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_115_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_116.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_116_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_117.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_117_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_118.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_118_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_119.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_119_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_12.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_12_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_120.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_120_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_121.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_121_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_122.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_122_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_123.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_123_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_124.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_124_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_125.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_125_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_126.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_126_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_127.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_127_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_128.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_128_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_129.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_129_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_13.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_13_1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Shop_DataSet/Shop DataSet/non shop lifters/shop_lifter_n_130.mp4  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "\n",
        "def extract_frames(video_path, target_frames=10, target_size=(112, 112)):\n",
        "    \"\"\"Extract a fixed number of frames from a video, with reduced resolution.\"\"\"\n",
        "    frames = []\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if total_frames == 0:\n",
        "        return None\n",
        "\n",
        "    step = max(total_frames // target_frames, 1)\n",
        "    frame_indices = range(0, min(total_frames, target_frames * step), step)\n",
        "\n",
        "    for i in frame_indices:\n",
        "        video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = video.read()\n",
        "        if ret:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = cv2.resize(frame, target_size)\n",
        "            frames.append(frame)\n",
        "\n",
        "    video.release()\n",
        "\n",
        "    # Pad or truncate to ensure we have exactly target_frames\n",
        "    if len(frames) < target_frames:\n",
        "        last_frame = frames[-1]\n",
        "        frames.extend([last_frame] * (target_frames - len(frames)))\n",
        "    elif len(frames) > target_frames:\n",
        "        frames = frames[:target_frames]\n",
        "\n",
        "    return np.array(frames)\n",
        "\n",
        "def process_video(video_path, label, target_frames=10, target_size=(112, 112)):\n",
        "    \"\"\"Process a single video and return frames and label.\"\"\"\n",
        "    frames = extract_frames(video_path, target_frames, target_size)\n",
        "    return frames, label\n",
        "\n",
        "def load_video_paths(data_dir):\n",
        "    \"\"\"Load video paths and labels from the directory structure.\"\"\"\n",
        "    video_paths = []\n",
        "    labels = []\n",
        "    for label in ['shop_lifters', 'non_shop_lifters']:\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        if not os.path.isdir(label_dir):\n",
        "            print(f\"Warning: {label_dir} not found.\")\n",
        "            continue\n",
        "        for video_file in os.listdir(label_dir):\n",
        "            if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
        "                video_paths.append(os.path.join(label_dir, video_file))\n",
        "                labels.append(label)\n",
        "    return video_paths, labels\n",
        "\n",
        "class VideoDataGenerator(Sequence):\n",
        "    def __init__(self, video_paths, labels, batch_size=32, target_frames=10, target_size=(112, 112)):\n",
        "        self.video_paths = video_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.target_frames = target_frames\n",
        "        self.target_size = target_size\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.encoded_labels = self.label_encoder.fit_transform(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.video_paths) / float(self.batch_size)))\n",
        "    def __getitem__(self, idx):\n",
        "        batch_paths = self.video_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_labels = self.encoded_labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        # Create a list of tuples (video_path, label) for the batch\n",
        "        batch_data = list(zip(batch_paths, [self.labels[i] for i in batch_labels]))\n",
        "\n",
        "        with multiprocessing.Pool() as pool:\n",
        "            # Use pool.starmap to unpack the tuples and provide both arguments to process_video\n",
        "            results = pool.starmap(partial(process_video,\n",
        "                                          target_frames=self.target_frames,\n",
        "                                          target_size=self.target_size),\n",
        "                                  batch_data)\n",
        "\n",
        "        batch_frames, _ = zip(*results)\n",
        "        batch_frames = np.array(batch_frames).astype('float32') / 255.0\n",
        "        batch_labels = to_categorical(batch_labels)\n",
        "\n",
        "        return batch_frames, batch_labels\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Shop_DataSet/Shop_DataSet'\n",
        "video_paths, labels = load_video_paths(data_dir)\n",
        "\n",
        "# Create train and validation generators\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(video_paths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_generator = VideoDataGenerator(train_paths, train_labels)\n",
        "val_generator = VideoDataGenerator(val_paths, val_labels)\n",
        "\n",
        "print(\"Number of training samples:\", len(train_paths))\n",
        "print(\"Number of validation samples:\", len(val_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL66M0tqhIeA",
        "outputId": "7e0b4a66-a0c9-42c4-d54a-1c73030287ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 684\n",
            "Number of validation samples: 171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=input_shape),\n",
        "        TimeDistributed(MaxPooling2D((2, 2))),\n",
        "        TimeDistributed(Conv2D(64, (3, 3), activation='relu')),\n",
        "        TimeDistributed(MaxPooling2D((2, 2))),\n",
        "        TimeDistributed(Conv2D(64, (3, 3), activation='relu')),\n",
        "        TimeDistributed(MaxPooling2D((2, 2))),\n",
        "        TimeDistributed(Flatten()),\n",
        "        LSTM(100, return_sequences=True),\n",
        "        LSTM(100),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Set up model parameters\n",
        "input_shape = (10, 112, 112, 3)  # (frames, height, width, channels)\n",
        "num_classes = 2\n",
        "\n",
        "# Create the model\n",
        "model = create_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy') # Change .h5 to .keras\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju8768f90GSL",
        "outputId": "bd2e56c2-fa7e-4c2e-fb72-b479ce9cbe2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 18s/step - accuracy: 0.6075 - loss: 0.6808 - val_accuracy: 0.6082 - val_loss: 0.6716\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 14s/step - accuracy: 0.5914 - loss: 0.6716 - val_accuracy: 0.6082 - val_loss: 0.6704\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 14s/step - accuracy: 0.6364 - loss: 0.6618 - val_accuracy: 0.6082 - val_loss: 0.6696\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 14s/step - accuracy: 0.5849 - loss: 0.6855 - val_accuracy: 0.6082 - val_loss: 0.6693\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 14s/step - accuracy: 0.6365 - loss: 0.6630 - val_accuracy: 0.6082 - val_loss: 0.6685\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 14s/step - accuracy: 0.5855 - loss: 0.6804 - val_accuracy: 0.6082 - val_loss: 0.6733\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 14s/step - accuracy: 0.6052 - loss: 0.6788 - val_accuracy: 0.6082 - val_loss: 0.6689\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 14s/step - accuracy: 0.6351 - loss: 0.6597 - val_accuracy: 0.6082 - val_loss: 0.6639\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.6344 - loss: 0.6464 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dHvdGzxp0kEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}